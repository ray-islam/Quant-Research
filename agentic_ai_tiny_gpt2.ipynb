{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxrpUB7o1FyaoPSzxNMIei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ray-islam/Quant-Research/blob/main/agentic_ai_tiny_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Agentic Trading Copilot — AI Edition (LLM + ML Predictor)\n",
        "# ===============================\n",
        "#!pip -q install yfinance gradio scikit-learn transformers accelerate --upgrade"
      ],
      "metadata": {
        "id": "1MBH9s9Qm44G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "6Bm9-1eMklJW",
        "outputId": "273baf09-fa90-41e9-b1e7-a03740666282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: {'ticker': 'SPY', 'final_equity': '$82,673', 'rolling_sharpe_20d': -20.61, 'max_drawdown': '-17.47%', 'risk_perc': 0.02, 'sl_atr': 1.5, 'planner_rationale': 'Heuristic: flat trend, wide range', 'decisions_sample': [('2025-05-23 08:45:00+00:00', 'MOMENTUM', 0.0), ('2025-05-23 14:00:00+00:00', 'MEANREV', 0.0), ('2025-05-23 19:00:00+00:00', 'BREAKOUT', 0.0), ('2025-05-27 08:00:00+00:00', 'ML', 0.0), ('2025-05-27 13:00:00+00:00', 'MEANREV', 0.0), ('2025-05-27 18:15:00+00:00', 'MOMENTUM', 0.0), ('2025-05-27 23:15:00+00:00', 'BREAKOUT', -0.0), ('2025-05-28 12:15:00+00:00', 'ML', -0.0)]}\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import warnings; warnings.filterwarnings(\"ignore\")\n",
        "import math, numpy as np, pandas as pd, matplotlib.pyplot as plt, yfinance as yf\n",
        "from math import sqrt, log\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# -------- settings --------\n",
        "USE_LLM = False   # set True to enable tiny LLM planner (downloads a small model)\n",
        "LLM_MODEL = \"sshleifer/tiny-gpt2\"  # tiny demo model; swap to TinyLlama for better quality\n",
        "\n",
        "# -------- utils: force 1-D --------\n",
        "def ravel1d(x): return np.asarray(x).ravel()\n",
        "def assert_1d_all(df):\n",
        "    bad = {c: v.shape for c,v in ((c, df[c].to_numpy()) for c in df.columns) if v.ndim != 1}\n",
        "    if bad: raise ValueError(f\"Non-1D columns found: {bad}\")\n",
        "\n",
        "# -------- data loader (intraday defaults for more actions) --------\n",
        "def load_data(ticker=\"SPY\", start=None, period=\"60d\", interval=\"15m\"):\n",
        "    if period is not None and start is None:\n",
        "        df = yf.download(ticker, period=period, interval=interval, auto_adjust=True, progress=False, prepost=True)\n",
        "    else:\n",
        "        start = pd.to_datetime(start)\n",
        "        start_eff = (start - pd.Timedelta(days=60)).strftime(\"%Y-%m-%d\")\n",
        "        end_eff   = (pd.Timestamp.today().normalize() + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "        df = yf.download(ticker, start=start_eff, end=end_eff, interval=interval, auto_adjust=True, progress=False, prepost=True)\n",
        "\n",
        "    if df is None or len(df) == 0:\n",
        "        raise ValueError(f\"No data for {ticker}.\")\n",
        "    df = df.rename(columns=str.lower).replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
        "    base_cols = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
        "    base = pd.DataFrame({c: pd.to_numeric(df[c].to_numpy().ravel(), errors=\"coerce\")\n",
        "                         for c in base_cols if c in df.columns}, index=df.index).dropna()\n",
        "    if len(base) < 100:\n",
        "        df2 = yf.download(ticker, period=\"90d\", interval=interval, auto_adjust=True, progress=False, prepost=True).rename(columns=str.lower)\n",
        "        base = pd.DataFrame({c: pd.to_numeric(df2[c].to_numpy().ravel(), errors=\"coerce\")\n",
        "                             for c in base_cols if c in df2.columns}, index=df2.index).dropna()\n",
        "    if len(base) < 100:\n",
        "        raise ValueError(f\"Not enough data for {ticker} at {interval}. Got {len(base)} rows.\")\n",
        "    return base\n",
        "\n",
        "# -------- indicators (manual, no 'ta') --------\n",
        "def sma(s, w): return pd.Series(s.rolling(w).mean().to_numpy().ravel(), index=s.index, name=f\"sma{w}\")\n",
        "def rsi(s, w=14):\n",
        "    d = s.diff()\n",
        "    up = pd.Series(np.where(d > 0, d, 0.0).ravel(), index=s.index)\n",
        "    dn = pd.Series(np.where(d < 0, -d, 0.0).ravel(), index=s.index)\n",
        "    gain = up.ewm(alpha=1/w, adjust=False).mean()\n",
        "    loss = dn.ewm(alpha=1/w, adjust=False).mean()\n",
        "    rs = gain / (loss + 1e-12)\n",
        "    return pd.Series((100 - (100/(1+rs))).to_numpy().ravel(), index=s.index, name=\"rsi\")\n",
        "def donchian_high(h, w=20): return pd.Series(h.rolling(w).max().to_numpy().ravel(), index=h.index, name=\"don_high\")\n",
        "def donchian_low(l, w=20):  return pd.Series(l.rolling(w).min().to_numpy().ravel(), index=l.index, name=\"don_low\")\n",
        "def atr(h, l, c, w=14):\n",
        "    pc = c.shift(1)\n",
        "    tr = np.maximum.reduce([\n",
        "        (h - l).to_numpy().ravel(),\n",
        "        (h - pc).abs().to_numpy().ravel(),\n",
        "        (l - pc).abs().to_numpy().ravel()\n",
        "    ])\n",
        "    tr = pd.Series(tr, index=h.index)\n",
        "    return pd.Series(tr.ewm(alpha=1/w, adjust=False).mean().to_numpy().ravel(), index=h.index, name=\"atr\")\n",
        "\n",
        "def add_features(base):\n",
        "    idx = base.index\n",
        "    feats = pd.DataFrame({\n",
        "        \"sma10\":    sma(base[\"close\"], 10).to_numpy().ravel(),\n",
        "        \"sma30\":    sma(base[\"close\"], 30).to_numpy().ravel(),\n",
        "        \"rsi\":      rsi(base[\"close\"], 14).to_numpy().ravel(),\n",
        "        \"don_high\": donchian_high(base[\"high\"], 20).to_numpy().ravel(),\n",
        "        \"don_low\":  donchian_low(base[\"low\"], 20).to_numpy().ravel(),\n",
        "        \"atr\":      atr(base[\"high\"], base[\"low\"], base[\"close\"], 14).to_numpy().ravel(),\n",
        "        \"ret\":      base[\"close\"].pct_change().to_numpy().ravel(),\n",
        "    }, index=idx)\n",
        "    d = pd.concat([base, feats], axis=1).replace([np.inf, -np.inf], np.nan).dropna()\n",
        "    assert_1d_all(d)\n",
        "    return d\n",
        "\n",
        "# -------- classic signals --------\n",
        "def sig_momentum(d):\n",
        "    s = pd.Series(0, index=d.index, dtype=int)\n",
        "    s[d[\"sma10\"] > d[\"sma30\"]] = 1\n",
        "    return s.astype(int)\n",
        "\n",
        "def sig_meanrev(d):\n",
        "    s = pd.Series(0, index=d.index, dtype=int)\n",
        "    s[d[\"rsi\"] < 35] = 1\n",
        "    s[d[\"rsi\"] > 60] = 0\n",
        "    return s.ffill().fillna(0).astype(int)\n",
        "\n",
        "def sig_breakout(d):\n",
        "    up = d[\"don_high\"].shift(1)\n",
        "    dn = d[\"don_low\"].shift(1)\n",
        "    s = pd.Series(0, index=d.index, dtype=int)\n",
        "    s[d[\"close\"] > up] = 1\n",
        "    s[d[\"close\"] < dn] = 0\n",
        "    return s.ffill().fillna(0).astype(int)\n",
        "\n",
        "# -------- ML predictor signal (online SGD) --------\n",
        "def sig_ml(d, warmup=200, threshold=0.52):\n",
        "    X = pd.DataFrame({\n",
        "        \"sma_spread\": (d[\"sma10\"] - d[\"sma30\"]) / (d[\"sma30\"] + 1e-9),\n",
        "        \"atr_pct\":    d[\"atr\"] / (d[\"close\"] + 1e-9),\n",
        "        \"rsi\":        d[\"rsi\"],\n",
        "        \"don_range\": (d[\"don_high\"] - d[\"don_low\"]) / (d[\"close\"] + 1e-9),\n",
        "        \"ret_lag1\":   d[\"ret\"].shift(1).fillna(0.0),\n",
        "    }, index=d.index).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "    y = (d[\"ret\"].shift(-1) > 0).astype(int).fillna(0).astype(int)\n",
        "\n",
        "    scal = StandardScaler()\n",
        "    clf  = SGDClassifier(loss=\"log_loss\", alpha=1e-4, random_state=0)\n",
        "    probs = np.zeros(len(X))\n",
        "\n",
        "    warm = min(max(warmup, 50), len(X)-1)\n",
        "    scal.partial_fit(X.iloc[:warm])\n",
        "    clf.partial_fit(scal.transform(X.iloc[:warm]), y.iloc[:warm], classes=[0,1])\n",
        "\n",
        "    for t in range(warm, len(X)):\n",
        "        p = clf.predict_proba(scal.transform(X.iloc[t:t+1]))[0,1]\n",
        "        probs[t] = p\n",
        "        scal.partial_fit(X.iloc[t:t+1])\n",
        "        clf.partial_fit(scal.transform(X.iloc[t:t+1]), y.iloc[t:t+1])\n",
        "\n",
        "    return pd.Series((probs > threshold).astype(int), index=d.index, name=\"sig_ml\")\n",
        "\n",
        "# -------- backtester (budget-capped + min_shares) --------\n",
        "def backtest(d, sig, risk_perc=0.02, sl_atr=1.5, min_shares=1, commission_bps=0):\n",
        "    \"\"\"\n",
        "    - Caps shares by both risk and cash budget so entries don't fail on expensive tickers.\n",
        "    - Ensures at least `min_shares` if affordable.\n",
        "    \"\"\"\n",
        "    sig = pd.Series(sig.to_numpy().ravel(), index=sig.index).reindex(d.index).ffill().fillna(0).astype(int)\n",
        "\n",
        "    cash, pos, equity = 100_000.0, 0, []\n",
        "    entry_px, stop, shares = None, None, 0\n",
        "\n",
        "    for i in range(1, len(d)):\n",
        "        row = d.iloc[i]\n",
        "        desired = int(sig.iloc[i])\n",
        "\n",
        "        # trail stop\n",
        "        if pos == 1 and stop is not None:\n",
        "            stop = max(stop, row[\"close\"] - sl_atr * row[\"atr\"])\n",
        "\n",
        "        # stop-out\n",
        "        if pos == 1 and stop is not None and row[\"low\"] < stop:\n",
        "            px = stop\n",
        "            cash += shares * px * (1 - commission_bps/10000.0)\n",
        "            pos, shares, entry_px, stop = 0, 0, None, None\n",
        "\n",
        "        # entries / exits\n",
        "        if desired == 1 and pos == 0:\n",
        "            px = row[\"close\"]\n",
        "            risk_dollars   = cash * risk_perc\n",
        "            per_share_risk = max(0.01, sl_atr * row[\"atr\"])\n",
        "\n",
        "            # --- budget cap fix ---\n",
        "            shares_risk   = int(risk_dollars // per_share_risk)\n",
        "            shares_budget = int(cash // (px * (1 + commission_bps/10000.0)))\n",
        "            shares = max(min_shares, min(shares_risk, shares_budget))\n",
        "\n",
        "            if shares > 0:\n",
        "                cost = shares * px * (1 + commission_bps/10000.0)\n",
        "                if cost <= cash:\n",
        "                    entry_px = px\n",
        "                    cash -= cost\n",
        "                    stop = entry_px - sl_atr * row[\"atr\"]\n",
        "                    pos = 1\n",
        "\n",
        "        elif desired == 0 and pos == 1:\n",
        "            px = row[\"close\"]\n",
        "            cash += shares * px * (1 - commission_bps/10000.0)\n",
        "            pos, shares, entry_px, stop = 0, 0, None, None\n",
        "\n",
        "        # mark-to-market\n",
        "        mark = cash + (shares * row[\"close\"] if pos == 1 else 0.0)\n",
        "        equity.append(mark)\n",
        "\n",
        "    eq = pd.Series(ravel1d(equity), index=d.index[1:], name=\"equity\")\n",
        "    retn = eq.pct_change().fillna(0.0)\n",
        "    roll20 = retn.rolling(20)\n",
        "    # rough intraday annualization for 15m bars\n",
        "    sharpe20 = (roll20.mean() / (roll20.std() + 1e-9)) * np.sqrt(252*6.5*60/15)\n",
        "    peak = eq.cummax(); dd = (eq/peak - 1.0)\n",
        "    return {\"equity\": eq, \"retn\": retn, \"sharpe20\": sharpe20, \"dd\": dd, \"final\": float(eq.iloc[-1])}\n",
        "\n",
        "# -------- regime + LLM planner (optional) --------\n",
        "def summarize_regime(d):\n",
        "    vol20 = float(d[\"ret\"].rolling(20).std().iloc[-1] * np.sqrt(252))\n",
        "    trend = float((d[\"sma10\"].iloc[-1] - d[\"sma30\"].iloc[-1]) / (d[\"sma30\"].iloc[-1] + 1e-9))\n",
        "    rng   = float((d[\"don_high\"].iloc[-1] - d[\"don_low\"].iloc[-1]) / (d[\"close\"].iloc[-1] + 1e-9))\n",
        "    return {\"vol20\": round(vol20,4), \"trend\": round(trend,4), \"range\": round(rng,4)}\n",
        "\n",
        "def heuristic_choice(reg):\n",
        "    if abs(reg[\"trend\"]) < 0.004 and reg[\"range\"] > 0.02: return \"MEANREV\", 0.02, 1.5, \"Heuristic: flat trend, wide range\"\n",
        "    if reg[\"range\"] > 0.03 and reg[\"trend\"] > 0:          return \"BREAKOUT\", 0.02, 1.5, \"Heuristic: wide range, uptrend\"\n",
        "    return \"MOMENTUM\", 0.02, 1.5, \"Heuristic: trend dominant\"\n",
        "\n",
        "def llm_plan(regime, last_perf):\n",
        "    if not USE_LLM:\n",
        "        return heuristic_choice(regime)\n",
        "    try:\n",
        "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "        tok = AutoTokenizer.from_pretrained(LLM_MODEL)\n",
        "        lm  = AutoModelForCausalLM.from_pretrained(LLM_MODEL, device_map=\"auto\")\n",
        "        prompt = f\"\"\"Return EXACTLY one line:\n",
        "STRATEGY=<MOMENTUM|MEANREV|BREAKOUT>; RISK=0.02; SL_ATR=1.5; WHY=<short reason>\n",
        "Regime: {regime} Recent: {last_perf}\"\"\"\n",
        "        x = tok(prompt, return_tensors=\"pt\").to(lm.device)\n",
        "        y = lm.generate(**x, max_new_tokens=64, do_sample=True, temperature=0.3)\n",
        "        raw = tok.decode(y[0], skip_special_tokens=True).splitlines()[-1]\n",
        "        up = raw.upper()\n",
        "        strat = \"MOMENTUM\"\n",
        "        if \"MEAN\" in up: strat = \"MEANREV\"\n",
        "        if \"BREAK\" in up: strat = \"BREAKOUT\"\n",
        "        import re\n",
        "        m_r = re.search(r\"RISK\\s*=\\s*([0-9.]+)\", up); m_s = re.search(r\"SL_ATR\\s*=\\s*([0-9.]+)\", up)\n",
        "        risk = float(m_r.group(1)) if m_r else 0.02\n",
        "        sl   = float(m_s.group(1)) if m_s else 1.5\n",
        "        # safety clamps\n",
        "        risk = min(max(risk, 0.005), 0.03)\n",
        "        sl   = min(max(sl,   1.0),   4.0)\n",
        "        return strat, risk, sl, raw\n",
        "    except Exception as e:\n",
        "        print(\"LLM disabled:\", e)\n",
        "        return heuristic_choice(regime)\n",
        "\n",
        "# -------- bandit (UCB1) --------\n",
        "class UCB1:\n",
        "    def __init__(self, arms, c=1.2):\n",
        "        self.arms = list(arms); self.c = c\n",
        "        self.n = {a: 0 for a in arms}; self.mu = {a: 0.0 for a in arms}; self.t = 0\n",
        "    def select(self, bias_arm=None, bias_bonus=0.0):\n",
        "        self.t += 1\n",
        "        for a in self.arms:\n",
        "            if self.n[a] == 0: return a\n",
        "        scores = {}\n",
        "        for a in self.arms:\n",
        "            bonus = self.c * sqrt(log(self.t)/self.n[a])\n",
        "            scores[a] = self.mu[a] + bonus + (bias_bonus if a == bias_arm else 0.0)\n",
        "        return max(scores, key=scores.get)\n",
        "    def update(self, arm, reward):\n",
        "        self.n[arm] += 1\n",
        "        self.mu[arm] += (reward - self.mu[arm]) / self.n[arm]\n",
        "\n",
        "# -------- agentic selection (with ML arm) --------\n",
        "def agentic_signal(d, rebalance=20, lookback=80, bandit_c=1.2, llm_bias=0.05):\n",
        "    sigs = {\n",
        "        \"MOMENTUM\": sig_momentum(d),\n",
        "        \"MEANREV\":  sig_meanrev(d),\n",
        "        \"BREAKOUT\": sig_breakout(d),\n",
        "        \"ML\":       sig_ml(d, warmup=max(200, lookback), threshold=0.52),\n",
        "    }\n",
        "    strat_ret = {k: (sigs[k].shift(1).fillna(0).to_numpy() * d[\"ret\"].to_numpy()) for k in sigs}\n",
        "    comp = np.zeros(len(d), dtype=int)\n",
        "    bandit = UCB1(sigs.keys(), c=bandit_c)\n",
        "    decisions = []\n",
        "\n",
        "    # initial plan (for bias toward LLM/heuristic suggestion)\n",
        "    reg = summarize_regime(d.iloc[:max(lookback, 100)])\n",
        "    init_strat, risk_perc, sl_atr, rationale = llm_plan(reg, last_perf={\"sharpe\":\"n/a\"})\n",
        "\n",
        "    for start in range(max(lookback, 100), len(d), rebalance):\n",
        "        end = min(start + rebalance, len(d))\n",
        "        past_start = max(0, start - lookback)\n",
        "        window_rewards = {k: float(np.nan_to_num(strat_ret[k][past_start:start]).mean()) for k in sigs}\n",
        "        arm = bandit.select(bias_arm=init_strat, bias_bonus=llm_bias)\n",
        "        comp[start:end] = sigs[arm].iloc[start:end].to_numpy()\n",
        "        realized = float(np.nan_to_num(strat_ret[arm][start:end]).mean())\n",
        "        bandit.update(arm, realized)\n",
        "        decisions.append((d.index[start], arm, realized, window_rewards))\n",
        "\n",
        "    return pd.Series(comp, index=d.index, name=\"sig_agentic\"), {\"risk_perc\": risk_perc, \"sl_atr\": sl_atr, \"rationale\": rationale, \"decisions\": decisions}\n",
        "\n",
        "# -------- main agent --------\n",
        "def run_agent(ticker=\"SPY\", period=\"60d\", interval=\"15m\",\n",
        "              rebalance=20, lookback=80,\n",
        "              risk_perc=None, sl_atr=None,\n",
        "              commission_bps=0, min_shares=1):\n",
        "    base = load_data(ticker, period=period, interval=interval)\n",
        "    d    = add_features(base)\n",
        "\n",
        "    comp_sig, meta = agentic_signal(d, rebalance=rebalance, lookback=lookback, bandit_c=1.2, llm_bias=0.05)\n",
        "    # Use planner-proposed risk/stop unless overridden\n",
        "    r = meta[\"risk_perc\"] if risk_perc is None else float(risk_perc)\n",
        "    s = meta[\"sl_atr\"]    if sl_atr    is None else float(sl_atr)\n",
        "\n",
        "    res = backtest(d, comp_sig, risk_perc=r, sl_atr=s, min_shares=min_shares, commission_bps=commission_bps)\n",
        "    sharpe = float(0.0 if pd.isna(res[\"sharpe20\"].iloc[-1]) else res[\"sharpe20\"].iloc[-1])\n",
        "    maxdd  = float(res[\"dd\"].min()) if len(res[\"dd\"]) else 0.0\n",
        "    summary = {\n",
        "        \"ticker\": ticker,\n",
        "        \"final_equity\": f\"${res['final']:,.0f}\",\n",
        "        \"rolling_sharpe_20d\": round(sharpe, 2),\n",
        "        \"max_drawdown\": f\"{round(maxdd*100, 2)}%\",\n",
        "        \"risk_perc\": r, \"sl_atr\": s,\n",
        "        \"planner_rationale\": meta[\"rationale\"],\n",
        "        \"decisions_sample\": [(str(t), a, round(rv,4)) for t,a,rv,_ in meta[\"decisions\"][:8]]\n",
        "    }\n",
        "    return d, comp_sig, res, summary\n",
        "\n",
        "# -------- run once (sanity) --------\n",
        "d, sig_comp, res, summary = run_agent()  # SPY, 60d, 15m defaults\n",
        "print(\"Summary:\", summary)\n",
        "\n",
        "# -------- UI --------\n",
        "import gradio as gr\n",
        "def app(ticker, period, interval, rebalance, lookback, risk_perc, sl_atr, use_llm):\n",
        "    global USE_LLM; USE_LLM = bool(use_llm)\n",
        "    d, sig_comp, res, summary = run_agent(\n",
        "        ticker=ticker, period=period, interval=interval,\n",
        "        rebalance=int(rebalance), lookback=int(lookback),\n",
        "        risk_perc=float(risk_perc) if risk_perc>0 else None,\n",
        "        sl_atr=float(sl_atr) if sl_atr>0 else None\n",
        "    )\n",
        "    eq = res[\"equity\"].rename(\"Equity\").to_frame()\n",
        "    ax = eq.plot(figsize=(8,4), title=\"Agentic Equity Curve (AI Edition)\")\n",
        "    fig = ax.get_figure(); plt.close(fig)\n",
        "    stats = (\n",
        "        f\"**Ticker**: {summary['ticker']}\\n\"\n",
        "        f\"**Final Equity**: {summary['final_equity']}\\n\"\n",
        "        f\"**Rolling Sharpe (20d)**: {summary['rolling_sharpe_20d']}\\n\"\n",
        "        f\"**Max Drawdown**: {summary['max_drawdown']}\\n\"\n",
        "        f\"**Risk %/Trade**: {summary['risk_perc']}\\n\"\n",
        "        f\"**Stop (ATR)**: {summary['sl_atr']}\\n\"\n",
        "        f\"**Planner rationale**: {summary['planner_rationale']}\\n\"\n",
        "        f\"**First decisions**: {summary['decisions_sample']}\\n\"\n",
        "    )\n",
        "    return stats, fig\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=app,\n",
        "    inputs=[gr.Textbox(value=\"SPY\", label=\"Ticker\"),\n",
        "            gr.Textbox(value=\"60d\", label=\"Lookback Period (e.g., 60d, 90d)\"),\n",
        "            gr.Dropdown(choices=[\"15m\",\"30m\",\"1h\",\"1d\"], value=\"15m\", label=\"Interval\"),\n",
        "            gr.Slider(5, 60, value=20, step=1, label=\"Rebalance (bars)\"),\n",
        "            gr.Slider(40, 200, value=80, step=5, label=\"Bandit Lookback (bars)\"),\n",
        "            gr.Slider(0.5, 3.0, value=2.0, step=0.1, label=\"Risk % per trade (0 = use planner)\"),\n",
        "            gr.Slider(0.5, 4.0, value=1.5, step=0.1, label=\"Stop (ATR multiples) (0 = use planner)\"),\n",
        "            gr.Checkbox(value=False, label=\"Use LLM planner (tiny)\")],\n",
        "    outputs=[gr.Markdown(label=\"Summary\"), gr.Plot(label=\"Equity Curve\")],\n",
        "    title=\"Agentic Trading Copilot — AI Edition (Budget-Capped)\",\n",
        "    description=\"Bandit selects among Momentum / MeanRev / Breakout / ML predictor. Optional LLM planner.\"\n",
        ")\n",
        "demo.launch(share=False)"
      ]
    }
  ]
}